{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow Guide.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNyC9ZPSWDp5WS+29IopMDW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MateoProjects/UtilsAI/blob/main/Tensorflow_Guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow Simple Guide\n",
        "\n",
        "Tensorflow in 10 minuts. A simple guide with util functions that can be used.\n",
        "\n",
        "**IN PROGRES** "
      ],
      "metadata": {
        "id": "1n2f4Rz1qIwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "a7pqjbZUqbHp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPzrayejqH_W"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.applications as app\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras import layers, regularizers\n",
        "from keras import backend as K\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense,  GlobalAveragePooling2D\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.models import Model\n",
        "from skimage import io\n",
        "from keras.utils.data_utils import Sequence\n",
        "from copy import copy\n",
        "from constants import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layers"
      ],
      "metadata": {
        "id": "_3QG2WQMq9eY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras have a convolutonal and dense layers.\n",
        "\n",
        "**Note**: The cells below are only examples of functions. Don't execute. "
      ],
      "metadata": {
        "id": "jt53G_nXrG1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequentia() # this line is for generate a red in sequential"
      ],
      "metadata": {
        "id": "A6eeXwC9rTcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to add new layers we only need to use the function **model.add()**\n",
        "\n",
        "In case that we want to add a new dense layer:\n",
        "* \n",
        "\n",
        "```Python\n",
        "tf.keras.layers.Dense(\n",
        "    units,\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    **kwargs\n",
        ")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Where: \n",
        "* Units activation is a integer.\n",
        "* Activation is a name of activation function like \"relu\", \"gelu\" etc...\n",
        "* kerne_initializer can be a string or a Initializer. See : https://keras.io/api/layers/initializers/"
      ],
      "metadata": {
        "id": "QhwmPzpPrbvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(layers.Dense(128, activation='relu'))"
      ],
      "metadata": {
        "id": "Pqh3_UmvrbYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case that we want to add a new conv layer:\n",
        "\n",
        "* \n",
        "\n",
        "```Python\n",
        "tf.keras.layers.Conv2D(\n",
        "    filters,\n",
        "    kernel_size,\n",
        "    strides=(1, 1),\n",
        "    padding='valid',\n",
        "    data_format=None,\n",
        "    dilation_rate=(1, 1),\n",
        "    groups=1,\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    **kwargs\n",
        ")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "b2unauQ3ssBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(layers.Conv2D(16,kernel_size(3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "#If its the first layers then:\n",
        "model.add(layers.Conv2D(16,kernel_size(3,3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(256,256,3), data_format='channels_last'))\n",
        "\n"
      ],
      "metadata": {
        "id": "gM0LDN3otOvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After a convolutional layer we need to add a pooling layer. In this example we show how to add an AveragePooling layer and MaxPooling layer.\n",
        "\n",
        "```\n",
        "tf.keras.layers.AveragePooling2D(\n",
        "    pool_size=(2, 2), strides=None, padding=\"valid\", data_format=None, **kwargs\n",
        ")\n",
        "```\n",
        "\n",
        "or \n",
        "\n",
        "```\n",
        "tf.keras.layers.MaxPooling2D(\n",
        "    pool_size=(2, 2), strides=None, padding=\"valid\", data_format=None, **kwargs\n",
        ")\n",
        "```\n",
        "\n",
        "Link to the documentation: https://keras.io/api/layers/pooling_layers/"
      ],
      "metadata": {
        "id": "4RepYxuwtuHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(layers.Conv2D(16,kernel_size(3,3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(256,256,3), data_format='channels_last'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# or \n",
        "\n",
        "model.add(layers.Conv2D(16,kernel_size(3,3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(256,256,3), data_format='channels_last'))\n",
        "model.add(layers.AveragePooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8ytg3jj9t4TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to normalize the output of a layer we can add a BatchNormalization layer.\n",
        "\n",
        "**Link to the documentation**: https://keras.io/api/layers/normalization_layers/batch_normalization/"
      ],
      "metadata": {
        "id": "V3lIxFr2uLd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='gelu', kernel_initializer='he_uniform',padding='same'))\n",
        "model.add(layers.BatchNormalization(center=True,))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))"
      ],
      "metadata": {
        "id": "5tu4NTsTuYS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemple of code for Museum Dataset"
      ],
      "metadata": {
        "id": "U27RU-d-vkSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MAMe dataset contains images of high-resolution and variable shape of artworks from 3 different museums:\n",
        "\n",
        "* The Metropolitan Museum of Art of New York\n",
        "* The Los Angeles County Museum of Art\n",
        "* The Cleveland Museum of Art"
      ],
      "metadata": {
        "id": "IlYTPjpjvupy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_baseModel():\n",
        "    \"\"\"\n",
        "    Get the model from the base model.\n",
        "    @return model\n",
        "    \"\"\"\n",
        "\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Conv2D(40, kernel_size=(3, 3), activation='gelu', kernel_initializer='he_uniform', padding='same', input_shape=(256,256,3), data_format='channels_last'))\n",
        "    model.add(layers.BatchNormalization(center=True,))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(80, kernel_size=(3, 3), activation='gelu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(160, kernel_size=(3, 3), activation='gelu', kernel_initializer='he_uniform',padding='same'))\n",
        "    model.add(layers.BatchNormalization(center=True,))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    #model.add(layers.Dense(256, activation='gelu'))\n",
        "    #model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Dense(128, activation='gelu' ))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.BatchNormalization(center=True,))\n",
        "    model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "Sj_P42CHrAQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this model you can obtain a 68% of accuracy in validation without data Augmentation. "
      ],
      "metadata": {
        "id": "gu-_kYLEyMIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a model"
      ],
      "metadata": {
        "id": "ct4vOq1UwPCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have our architecture of the model we need decide if we want a optimizer\n",
        " \n",
        "The most tipical optimizers are: \n",
        "\n",
        "* SGD:\n",
        "\n",
        "\n",
        "```\n",
        "tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "```\n",
        "* Adam:\n",
        "\n",
        "```\n",
        "tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\",\n",
        "    **kwargs\n",
        ")\n",
        "```\n",
        "\n",
        "**Link to documentation**: https://keras.io/api/optimizers/\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FR_HyCzKwoyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "# or\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "2tjZoIJHxbLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have chosed the optimizer we need to compile the model that configures the model for training. We can fix the loss function that we want and the metrics that we want to evaluate. \n",
        "\n",
        "```\n",
        "Model.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=None,\n",
        "    metrics=None,\n",
        "    loss_weights=None,\n",
        "    weighted_metrics=None,\n",
        "    run_eagerly=None,\n",
        "    steps_per_execution=None,\n",
        "    jit_compile=None,\n",
        "    **kwargs\n",
        ")\n",
        "\n",
        "```\n",
        "\n",
        "**Note**: Loss can be a string or a [tf.losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses)\n",
        "\n",
        "**Link to documentation**: https://keras.io/api/models/model_training_apis/#compile-method"
      ],
      "metadata": {
        "id": "BNC-3y66xnoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_baseModel()\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "cZe5GpZIwV7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train \n",
        "\n",
        "For train the model we need to call model.fit()\n",
        "\n",
        "```\n",
        "Model.fit(\n",
        "    x=None,\n",
        "    y=None,\n",
        "    batch_size=None,\n",
        "    epochs=1,\n",
        "    verbose=\"auto\",\n",
        "    callbacks=None,\n",
        "    validation_split=0.0,\n",
        "    validation_data=None,\n",
        "    shuffle=True,\n",
        "    class_weight=None,\n",
        "    sample_weight=None,\n",
        "    initial_epoch=0,\n",
        "    steps_per_epoch=None,\n",
        "    validation_steps=None,\n",
        "    validation_batch_size=None,\n",
        "    validation_freq=1,\n",
        "    max_queue_size=10,\n",
        "    workers=1,\n",
        "    use_multiprocessing=False,\n",
        ")\n",
        "```\n",
        "\n",
        "**Notes**:\n",
        "\n",
        "* X and Y can be a generators, numpy arrays etc... If we use a DataGenerators we don't need to specify Y\n",
        "\n",
        "**Link to documentation**: https://keras.io/api/models/model_training_apis/#fit-method"
      ],
      "metadata": {
        "id": "8pApz9GDy4Ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mdl_fit = model.fit(x_train, y_train, validation_data=validationData, \n",
        "                    shuffle=True,epochs=EPOCHS, batch_size=BATCH_SIZE, \n",
        "                    use_multiprocessing=True,workers=4,callbacks = [early])"
      ],
      "metadata": {
        "id": "t68Mq6aizudu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPORTANT THING**\n",
        "\n",
        "By default Keras' model.fit() returns a History callback object. This object keeps track of the accuracy, loss and other training metrics, for each epoch, in the memory.\n",
        "\n",
        "This object is a dictionary where keys are the metrics.\n",
        "\n",
        "**Example**:\n",
        "```\n",
        "print(mdl_fit['accuracy'])\n",
        "print(mdl_fit['val_loss'])\n",
        "```"
      ],
      "metadata": {
        "id": "5O3VtIIc2Zwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: This is only an example. Don't execute it. It's only for see how to call the function.\n",
        "\n",
        "**Other parameters**:\n",
        "* Shuffle will shuffle the data during the training process. \n",
        "* In this example validation data is passed using a Data generator. \n",
        "* If we wan to add a early stopping we need to put in to callbacks. Callbacks are explained below. "
      ],
      "metadata": {
        "id": "Hu0sH2Ftz-1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding a Early Stopping\n",
        "\n",
        "If we want to add a early stopping we need to add a new callback.\n",
        "\n",
        "**Link to documentation**: https://keras.io/api/callbacks/"
      ],
      "metadata": {
        "id": "zDFIAPHe01LF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, verbose=1, mode='auto', restore_best_weights=True)"
      ],
      "metadata": {
        "id": "OX0Ld1S50h0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the parameters of this function we can see how we can decide the variable that we want to monitor.\n",
        "* The patience it's for indicate the number of epochs with no improvement after which training will be stopped.\n",
        "* Verbose 0 if we dont want to see anything else 1. "
      ],
      "metadata": {
        "id": "vhjI6-iF1n_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating a model\n",
        "\n",
        "If we used a validation set during the training one form to see the accuracy and loss during the training is plot these using matplotlib. \n",
        "\n",
        "The function below plot loss and accuracy. "
      ],
      "metadata": {
        "id": "tM57MibAwSJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_results_model(mdl_fit, epochs=16, batch_size=32):\n",
        "    \"\"\"\n",
        "    Print the results of the model trained on the given data.\n",
        "    @param mdl_fit: model trained on the given data\n",
        "    @param epochs: number of epochs used for training\n",
        "    @param batch_size: batch size used for training\n",
        "    @param balanced: whether the data is balanced or not\n",
        "    \"\"\"\n",
        "    # plot the loss\n",
        "    plt.plot(mdl_fit.history['loss'], label='train loss')\n",
        "    plt.plot(mdl_fit.history['val_loss'], label='val loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(\"data_epochs_\" +str(epochs)+\"_batchSize_\"+ str(batch_size)+'_LossVal_loss')\n",
        "    plt.show()\n",
        "    # plot the accuracy\n",
        "    plt.plot(mdl_fit.history['accuracy'], label='train acc')\n",
        "    plt.plot(mdl_fit.history['val_accuracy'], label='val acc')\n",
        "    plt.legend()\n",
        "    plt.savefig(\"balanced_data_epochs_\" +str(epochs)+\"_batchSize_\"+ str(batch_size)+'_AccVal_acc')\n",
        "    #save model to disk\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "zVmADWMnyv2-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}